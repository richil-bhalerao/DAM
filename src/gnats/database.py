"""
GNATS Database, Field and DatabaseHandle classes.

Dirk Bergstrom, dirk@juniper.net, 2008-04-17

Copyright (c) 2008-2009, Juniper Networks, Inc.
All rights reserved.
"""
import time
import re
import logging

import gnats
import codes
from gnats import GnatsException
from gnats import InvalidFieldNameException
from gnats import LastModifiedTimeException
from gnats import PRNotFoundException
from metadata import ConfigMeta

# Assign empty dict and array to store release values to avoid running of the
# same command multiple times.
release_dict = {}
release_arr = []
_LOG = logging.getLogger('database')


def _require_metadata(level):
    """ Raise an exception if the global gnats.metadata_level is
    less than the value given. """
    if gnats.metadata_level < level:
        raise GnatsException("Insufficient metadata available "
                             "(gnats.metadata_level < gnats.%s" % level[1])


class Database(object):
    """ Metadata for a GNATS database.

    This class serves two primary purposes:
      *) Holding the metadata for a GNATS database and all its fields.
      *) Providing a factory method for DatabaseHandle objects, which are
      used to communicate with gnatsd and query for and modify PRs.

    A Database object is intended to be long-lived -- create one and use it
    repeatedly.  When instantiated, a Database object queries gnatsd for
    database and field metadata and caches it.  By default, it will check the
    currency of its metadata every time a DatabaseHandle is requested,
    refreshing it if necessary.  The package-global variables metadata_level and
    refresh_metadata_automatically control the amount and frequency of metadata
    loading.  You may pass in a function at instantiation, or set
    post_metadata_callback to one later, and it will be called after metadata is
    refreshed, with the Database object as its sole argument.

    Call the get_handle() method to obtain a DatabaseHandle object, with which
    you can communicate with the server.

    The various validation methods provide minimal validation of PR and field
    data, without contacting the server.  Once a PR is submitted for creation
    or edit, the server may apply business rules beyond what Database knows
    about.

    Field names are case sensitive and *must* be supplied in all-lowercase.
    """

    ENVELOPE_FIELD_INFO = (
        # (lcname, name, display name, description)
        ('from:', "Reporter's email", "", codes.FLAG_REQUIRED),
        ('reply-to:', "Reply-To:", "", ""),
    )

    def __init__(self, server, name, conn, callback=None):
        self.server = server
        self.name = name
        self.post_metadata_callback = callback
        self.description = ''
        self.number_field = None
        self.ordered_fields = []
        # fields are indexed by downcased name
        self.fields = {}
        self.initial_entry_fields = []
        self.last_config_time = 0
        self.single_valued_fields = []
        self.table_fields = []
        self.multi_valued_fields = {}
        conn.chdb(self.name, userpass=self.server.dbuser(self.name))
        self.envelope_fields = {}
        for ef in self.ENVELOPE_FIELD_INFO:
            self.envelope_fields[ef[0]] = \
                Field(ef[0], ef[1], ef[2], 'envelope', '', ef[3], '', None)
        self._get_metadata(conn)

    def __str__(self):
        return "GNATS Database '%s' on %s" % (self.name, self.server)

    def __repr__(self):
        return "<%s>" % self.__str__()

    def _create_fields(self, conn, names, real_names=None): #IGNORE:W0102
        """ Create Field objects for each name in names.

        For TableField columns, real_names should be the unqualified display
        names of the fields, and names should be the qualified names
        (table-field.column-name).

        Used to fetch both Database Fields and TableField columns.
        """
        if not real_names:
            real_names = names

        # Reading data from data structure generated by automated script
        # instead of sending commands to gnatsd. Also checking commands
        # in the file, if it does not found the command then request
        # will send to gnatsd (for ex: portals).

        cmd = 'FTYP ' + ' '.join(names)
        if not ConfigMeta.mdata_dict.has_key(cmd):
            ConfigMeta.mdata_dict[cmd] = conn.ftyp(names)
        types = ConfigMeta.mdata_dict[cmd]
        cmd = 'FIELDFLAGS ' + ' '.join(names)
        if not ConfigMeta.mdata_dict.has_key(cmd):
            ConfigMeta.mdata_dict[cmd] = conn.fieldflags(names)
        flags = ConfigMeta.mdata_dict[cmd]
        cmd = 'LIST axisnames'
        if not ConfigMeta.mdata_dict.has_key(cmd):
	    ConfigMeta.mdata_dict[cmd] = conn.list("axisnames")
        axis_names = []
        # Get the axis name for each field.
        for i in names:
	    get_axis_name = ConfigMeta.mdata_dict[cmd]
            if get_axis_name:
               axis_names.append(get_axis_name[0])
            else:
               axis_names.append('')
        ConfigMeta.mdata_dict[cmd] = axis_names
        field_axes = ConfigMeta.mdata_dict[cmd]
        if gnats.metadata_level > gnats.MINIMAL_METADATA:
            cmd = 'FDSC '  + ' '.join(names)
            if not ConfigMeta.mdata_dict.has_key(cmd):
                ConfigMeta.mdata_dict[cmd] = conn.fdsc(names)
            descs = ConfigMeta.mdata_dict[cmd]
            cmd = 'INPUTDEFAULT '  + ' '.join(names)
            if not ConfigMeta.mdata_dict.has_key(cmd):
                ConfigMeta.mdata_dict[cmd] = conn.inputdefault(names)
            defaults = ConfigMeta.mdata_dict[cmd]
        else:
            # use empty string
            descs = len(names) * ['']
            defaults = len(names) * ['']
        fields = []
        for name, ftype, default, flag, desc, axes, real_name in \
                zip(names, types, defaults, flags, descs, field_axes, real_names):
            ftype = ftype.lower()
            if ftype.find('enum') > -1:
                fld = EnumField(name.lower(), real_name, desc, ftype, default,
                                flag, axes, conn)
            elif ftype == 'table':
                fld = TableField(name, desc, flag, self, conn)
            else:
                fld = Field(name.lower(), real_name, desc, ftype, default, flag,
                            axes, conn)
            fields.append(fld)
        return fields

    def _get_metadata(self, conn):
        """ Fetch metadata from gnatsd and cache it.

        TODO May need to be more thread-safe.
        """
        # Initialize class 'ConfigMeta' to get the meta data from the pickle
        # file.
        ConfigMeta(self, self.name)
        ConfigMeta.mdata_dict = self.mdata_dict
        ConfigMeta.user_list_fields = self.user_list_fields
        self.mdata_dict = {}
        if gnats.metadata_level == gnats.NO_METADATA:
            return
        new_fields = {}
        new_single_valued_fields = []
        new_table_fields = []
        new_multi_valued_fields = {}
        # Reading data from data structure generated by automated script instead
        # of sending commands to gnatsd. 
        cmd = 'LIST fieldnames'
        if not ConfigMeta.mdata_dict.has_key(cmd):
            ConfigMeta.mdata_dict[cmd] = conn.list("fieldnames")
        names = ConfigMeta.mdata_dict[cmd]
        new_ordered_fields = self._create_fields(conn, names)
        for fld in new_ordered_fields:
            new_fields[fld.lcname] = fld
            if fld.multi_valued:
                new_multi_valued_fields.setdefault(fld.axis.lower(), []). \
                    append(fld)
            else:
                new_single_valued_fields.append(fld)
                if isinstance(fld, TableField):
                    new_table_fields.append(fld)
        new_fields.update(self.envelope_fields)

        new_initial_entry_fields = []
        if gnats.metadata_level > gnats.MINIMAL_METADATA:
            self.description = conn.dbdesc(self.name)
            # find and mark initial input fields
            cmd = "LIST initialinputfields"
            if not ConfigMeta.mdata_dict.has_key(cmd):
                ConfigMeta.mdata_dict[cmd] = conn.list("initialinputfields")
            input_fields = ConfigMeta.mdata_dict[cmd]
            # The from: envelope field is required on create
            input_fields.append('from:')
            for fname in input_fields:
                fld = new_fields[fname.lower()]
                fld.initial = True
                new_initial_entry_fields.append(fld)

        # The first field is always (?) builtinfield:number
        new_fields['builtinfield:number'] = new_ordered_fields[0]

        # Removed hardcoded tuple 'BUILTIN_NAMES' of builtinfields and used
        # the gnatsd command (LIST builtinfields) to get the builtin field name.
        builtin_name_flds = conn.list("builtinfields")

        # Construct the dict with builtinfields and real names.
        builtin_flds = dict(map(lambda k: k.split(':'), builtin_name_flds))
        for builtin_name, real_name in builtin_flds.items():
            # Ignore table fields. For example 'Audit-Trail.Info'.
            if real_name.find('.') != -1: continue
            try:
                new_fields['builtinfield:%s' % builtin_name.lower()] = new_fields[real_name.lower()]
            except KeyError:
                # This db has renamed the builtin.  It's a disaster, but
                # there's nothing we can do now.
                _LOG.warning("Database '%s' has renamed builtin '%s'",
                             builtin_name, real_name)

        self.fields = new_fields
        self.number_field = new_ordered_fields[0]
        self.initial_entry_fields = new_initial_entry_fields
        self.ordered_fields = new_ordered_fields
        self.multi_valued_fields = new_multi_valued_fields
        self.single_valued_fields = new_single_valued_fields
        self.table_fields = new_table_fields

        try:
            self.last_config_time = conn.cfgt()
        except GnatsException:
            self.last_config_time = time.time()

        if callable(self.post_metadata_callback):
            # Execute the callback, and hope that it works
            self.post_metadata_callback(self)

    def update_metadata(self, conn):
        """ Check with the server to determine if the cached metadata is
        current, and reload it if not. """
        try:
            fetch_meta = self.last_config_time != conn.cfgt()
        except GnatsException:
            # server doesn't implement CFGT, refresh every Server.cache_time
            # seconds.
            fetch_meta = (time.time() - int(self.last_config_time)) \
                > self.server.cache_time
        if fetch_meta:
            _LOG.info("Refreshing metadata for db %s", self.name)
            self._get_metadata(conn)

    def get_handle(self, username, passwd=None, conn=None):
        """ Return a DatabaseHandle object for this database, refreshing
        cached metadata if necessary.
        """
        _LOG.info("User '%s' getting handle for db %s", username, self.name)
        dbh = DatabaseHandle(self, username, passwd, conn)
        if gnats.refresh_metadata_automatically and \
                gnats.metadata_level > gnats.NO_METADATA:
            self.update_metadata(dbh.conn)
        return dbh

    def builtin(self, name):
        """ Return the field name corresponding to the builtin field name, or
        the empty string if there is no such field.
        """
        _require_metadata(gnats.MINIMAL_METADATA)
        try:
            return self.fields['builtinfield:%s' % name].lcname
        except KeyError:
            return ''

    def list_fields(self):
        """ Return a list of the fields in dbconfig order. """
        _require_metadata(gnats.MINIMAL_METADATA)
        return list(self.ordered_fields)

    def build_format(self, field_names, table_field=None):
        """ Build a QFMT for the given fields.

        If table_field is given, it should be the name of the table field
        that has field_names as columns.
        """
        _require_metadata(gnats.MINIMAL_METADATA)
        if table_field:
            field_dict = self.fields[table_field].columns
            fsep = codes.COL_SEP
            rsep = codes.ROW_SEP
        else:
            field_dict = self.fields
            fsep = codes.FIELD_SEP
            rsep = codes.RECORD_SEP
        pics = []
        flds = []
        for fname in field_names:
            flds.append(fname)
            fld = field_dict.get(fname, None)
            if fld is None:
                # We don't know what field they're asking for, assume it's
                # a string-ish type.
                pics.append('%s')
            elif fld.ftype == 'date':
                pics.append('%{%Y-%m-%d %H:%M:%S %Z}D')
            else:
                pics.append('%s')
        format = '"%s%s" %s' % (fsep.join(pics), rsep, ' '.join(flds))
        return format

    def unparse_pr(self, pr):
        """ Turn a PR dict into a canonical GNATS PR format text block.

        Read-only fields are skipped.
        Table fields are skipped.
        Change-reason data (if present) is included.
        Spurious information in the pr dict is ignored.

        This method is used solely for internal communications with gnatsd.
        It is NOT a substitute for `query-pr --full <prnum>`.
        """
        # XXX???
        # The following code will give output that is *very* close to --full, at
        # the expense of breaking many unit tests.  Written while looking to fix
        # a bug that turned out to be in gnatsd, saving in case it proves useful
        # at a later date.
        #for fld in self.ordered_fields:
        #    if fld.multi_valued:
        #        axis_data = pr.get(fld.axis, [])
        #        for identifier, scope_dict in axis_data:
        #            if not identifier.strip():
        #                # Skip bogus scopes
        #                continue
        #            if not fld._really_read_only and fld.lcname in scope_dict:
        #                self._unparse_field(fld, scope_dict, body,
        #                                    scope=identifier)
        #    elif not (fld._really_read_only or fld.ftype == 'table') and \
        #            fld.lcname in pr:
        #        self._unparse_field(fld, pr, body)
        _require_metadata(gnats.MINIMAL_METADATA)
        body = []
        for env_fld in self.envelope_fields.itervalues():
            try:
                body.append('%s %s\n' %
                            (env_fld.lcname.title(), pr[env_fld.lcname]))
            except KeyError:
                # skip header fields not in pr dict, except From:
                if env_fld.lcname == 'from:':
                    raise GnatsException("Must supply a From: header address")
        # add blank line after header
        body.append('\n')

        # add the PR number, if present in the dict
        if pr.has_key(self.number_field.lcname):
            self._unparse_field(self.number_field, pr, body)

        for fld in self.single_valued_fields:
            if not (fld._really_read_only or fld.ftype == 'table') and \
                    fld.lcname in pr:
                self._unparse_field(fld, pr, body)
        for axis, fields in self.multi_valued_fields.iteritems():
            axis_data = pr.get(axis, [])
            for identifier, scope_dict in axis_data:
                if not identifier.strip():
                    # Skip bogus scopes
                    continue
                for fld in fields:
                    if not fld._really_read_only and fld.lcname in scope_dict:
                        self._unparse_field(fld, scope_dict, body,
                                            scope=identifier)
        return ''.join(body).strip()

    def _unparse_field(self, fld, val_dict, body, scope=None):
        """ Render a single field in canonical GNATS format. """
        if fld.ftype == 'table':
            # TableFields are not unparsed
            return
        if scope is not None:
            name = "%s{%s}" % (fld.name, scope)
        else:
            name = fld.name

        val = val_dict.get(fld.lcname, '')
        if fld.ftype == 'multienum' and not isinstance(val, basestring):
            # Presume that we've been given a list or tuple of enum vals
            val = fld.default_separator.join(val)

        if fld.ftype == 'multitext':
            body.append('>%s:\n%s' % (name, self._fix_multiline_val(val)))
        else:
            body.append("%-16s %s\n" % (">%s:" % name, val))

        # Check for change-reason pseudo-fields
        cr = val_dict.get("%s-changed-why" % fld.lcname, None)
        # User was not able to link a case id having non-ASCII characters in
        # clarify field data. It was throwing "UnicodeDecodeError" while 
        # link/unlink those case id in GNATS PR.
        if type(cr) is str:
            cr = cr.decode('utf-8', 'ignore')
        if cr is not None:
            body.append(">%s-Changed-Why%s:\n%s" % (fld.name,
                        scope is not None and '{%s}' % scope or '',
                        self._fix_multiline_val(cr)))

    _ADD_SPACE_RE = re.compile(r"""
    (
     ^>              # look for line beginning with > and
     [\w-]+          # followed by a word and
     ({[\w\-]})?     # possibly some alphanumeric in braces 
     :               # followed by a colon
    )
    """, re.VERBOSE | re.MULTILINE)
    def _fix_multiline_val(self, val):
        """ Canonicalize newlines, and ensure that there is a newline on
        the end of the string, unless it's the empty string.
        """
        if not val:
            return ''
        # Escape everything that looks like a GNATS field header by adding 
        # a space at the beginning.
        val = self._ADD_SPACE_RE.sub(r' \1', val)
        val = val.replace('\r\n', '\n')
        val = val.replace('\r', '\n')
        if val[-1] != '\n':
            val = '%s\n' % val
        return val

    def validate_fields(self, pr, change_reasons=True):
        """ Validate the supplied fields.

        If change_reasons is True, fields that require a change-reason and
        have none will be flagged.

        Return a dict of {field1.lcname:[errors], field2.lcname:...}.
        """
        validate = change_reasons and 'fields-cr' or 'fields'
        return self._validate(pr, validate)

    def validate_pr(self, pr):
        """ Validate the pr, checking for missing required fields and change
        reasons.

        Return a dict of {field1.lcname:[errors], field2.lcname:...}.
        """
        return self._validate(pr, validate='all')

    def validate_initial(self, pr):
        """ Validate the pr for initial submission.

        Required initial-entry fields will be checked.

        Return a dict of {field1.lcname:[errors], field2.lcname:...}.
        """
        return self._validate(pr, validate='initial')

    def _validate(self, pr, validate):
        """ Validate the contents of the supplied PR without contacting gnatsd.

        Return a dict of {field1.lcname:[errors], field2.lcname:...}.

        FIXME Does not validate table-fields.
        """
        _require_metadata(gnats.FULL_METADATA)
        fields_only = False
        initial_only = False
        check_cr = False
        fields = []
        if validate == 'initial':
            # check only initial-entry fields
            for fld in self.initial_entry_fields:
                if not fld.multi_valued:
                    fields.append(fld)
            initial_only = True
        else:
            # check writeable fields
            fields = [f for f in self.single_valued_fields
                      if not (f.read_only or f.ftype == 'table')]
            if validate in ('all', 'fields-cr'):
                check_cr = True
            if validate in ('fields', 'fields-cr'):
                fields_only = True
        errs = {}
        for fld in fields:
            if fields_only and not pr.has_key(fld.lcname):
                # validate only fields supplied in the dict
                continue
            fld_err = self.validate_field(fld.lcname, pr, check_cr)
            if fld_err:
                errs[fld.lcname] = fld_err
        for axis, fields in self.multi_valued_fields.iteritems():
            axis_data = pr.get(axis, [])
            for identifier, scope_dict in axis_data:
                for fld in fields:
                    if fld.read_only or \
                            (initial_only and not fld.initial) or \
                            (fields_only and not scope_dict.has_key(fld.lcname)):
                        continue
                    fld_err = self.validate_field(fld.lcname, scope_dict,
                                                  check_cr)
                    if fld_err:
                        errs["%s{%s}" % (fld.lcname, identifier)] = fld_err
        return errs

    def validate_field(self, fname, pr, check_cr=False):
        """ Check that the value for the field is valid, not missing if
        required, and (if check_cr set) that a change-reason has been
        supplied.

        If you are validating a scoped field, pass in the dict of values
        for the desired scope, not the entire PR.
        TODO Should we raise if they pass in the whole PR?  How to detect?

        Returns a list of error messages.

        FIXME table-fields
        """
        _require_metadata(gnats.FULL_METADATA)
        try:
            fld = self.fields[fname]
        except KeyError:
            raise InvalidFieldNameException('Field "%s" doesn\'t exist.' % fname)
        value = pr.get(fname, '')
        if isinstance(value, basestring):
            value = value.strip()
        errs = []
        if fld.required and not value:
            errs.append('Required field %s has empty value.' % fld.name)
        if hasattr(fld, 'values') and not fld.allow_any_value:
            if fld.ftype == 'multienum':
                if isinstance(value, basestring):
                    value = value.split(fld.default_separator)
                if not hasattr(value, "__iter__"):
                    errs.append("Value for multienum field %s is neither string"
                                " nor iterable." % fld.name)
                else:
                    bad_vals = []
                    for val in value:
                        if val not in fld.values and val != fld.default:
                            bad_vals.append(val)
                    if bad_vals:
                        errs.append("Error in field %s: illegal values: '%s'" %
                            (fld.name, "', '".join(bad_vals)))
            elif value not in fld.values and value != fld.default:
                errs.append("Error in field %s: '%s' is an illegal value." %
                            (fld.name, value))
        if check_cr and fld.require_change_reason:
            cr = pr.get('%s-changed-why' % fname, '').strip()
            if not cr:
                errs.append('Edit of field %s requires a change reason.' %
                            fld.name)
        return errs


class Field(object):
    """ Holds the metadata describing a GNATS field. """

    # There is also a 'numeric' sort type, used for non-integer fields
    # that need to be sorted as if they are numbers.
    SORT_TYPES = {
        'integer': 'integer',
        'enum': 'enum',
        'multienum': 'enum',
        'text': 'alpha',
        'multitext': 'alpha',
        'date': 'alpha',
        'envelope': 'alpha',
        'table': 'table',
    }

    def __init__(self, lcname, name, desc, ftype, default, flags, axes, conn):
        self.name = name
        self.lcname = lcname
        self.description = desc
        self.default = default
        self.ftype = ftype
        # FIXME there are more undocumented flags...
        flag_list = flags.split()
        # We need to be able to declare a field "read-only" for purposes of
        # the UI, even though it's not read-only in dbconfig.  However, if
        # we just change the flag, then unparse_pr() will exclude the field,
        # and it will be blanked out in every edit.  So we have two flags,
        # read_only, which is used externally, and _really_read_only, which
        # is used in edit_pr and unparse_pr.
        self._really_read_only = codes.FLAG_READ_ONLY in flag_list
        self.read_only = self._really_read_only
        self.required = codes.FLAG_REQUIRED in flag_list
        self.require_change_reason = \
            codes.FLAG_REQUIRE_CHANGE_REASON in flag_list
        self.multi_valued = codes.FLAG_MULTI_VALUED in flag_list
        self.text_search = codes.FLAG_TEXT_SEARCH in flag_list
        self.req_cond = codes.FLAG_REQ_COND in flag_list
        self.allow_any_value = codes.FLAG_ALLOW_ANY_VALUE in flag_list
        self.initial = False
        self.sorting = self.SORT_TYPES[ftype]
        if self.multi_valued:
            # FIXME I don't understand what happens when a field has more
            # than one axis.
            self.axis = axes.lower()

    def __str__(self):
        return "GNATS %s Field '%s'" % (self.ftype, self.name)

    def __repr__(self):
        return "<%s>" % self.__str__()


class EnumField(Field):
    """ A GNATS field having a list of values. """

    def __init__(self, lcname, name, desc, ftype, default, flags, axes, conn):
        Field.__init__(self, lcname, name, desc, ftype, default, flags,
                       axes, conn)
        self.values_dict = {}
        self.values = []
        if gnats.metadata_level > gnats.NO_ENUM_METADATA:
            self.load_enum_values(conn)

    def load_enum_values(self, conn):
        try:
            # Reading data from data structure generated by automated script
            # instead of sending commands to gnatsd.
            cmd = 'FTYPINFO ' + self.lcname + ' subfields'
            if not ConfigMeta.mdata_dict.has_key(cmd):
                ConfigMeta.mdata_dict[cmd] = conn.ftypinfo(self.lcname, 'subfields')
            self.subfields = ConfigMeta.mdata_dict[cmd]
        except GnatsException, e:
            if e.code == codes.CODE_INVALID_FTYPE_PROPERTY:
                # Field has no subfields, just grab the values
                cmd = 'FVLD ' + self.lcname
                # Adding command output in the form of key:value if it does
                # not exist in pickle file.
                if not ConfigMeta.mdata_dict.has_key(cmd):
                    ConfigMeta.mdata_dict[cmd] = conn.fvld(self.lcname)
                self.values = ConfigMeta.mdata_dict[cmd]
                self.subfields = [self.lcname]
                # and set up a "fake" values_dict with one entry
                for val in self.values:
                    self.values_dict[val] = {self.lcname: val}
            else:
                # A real error that needs to propagate
                raise
        else:
            # Set up a dict of subfield_name:subfield_value for each value
            # "FVLD <field> *" will fetch all subfield values
            # TODO reading the FVLD data takes 1/4 of the metadata read time;
            # another 1/4 of the time is spent inside this loop, mostly
            # in creating the dicts.
            # The bulk of all this time is for the Responsible field 
            # (~6400 lines).

            # Since data is reading from file, So added error '435 ERROR' in
            # the file to handle if there is any exception occured.
            if '435 ERROR' in ConfigMeta.mdata_dict[cmd]:
                cmd = 'FVLD ' + self.lcname
                # Adding command output in the form of key:value if it does
                # not exist in pickle file.
                if not ConfigMeta.mdata_dict.has_key(cmd):
                    ConfigMeta.mdata_dict[cmd] = conn.fvld(self.lcname)
                self.values = ConfigMeta.mdata_dict[cmd]
                self.subfields = [self.lcname]
                # and set up a "fake" values_dict with one entry
                for val in self.values:
                    self.values_dict[val] = {self.lcname: val}
            # Avoid commands which fetches all users information. 
            # Also checking whether field exist in platforms, sw-images,
            # products or releases fields list. If yes then use platforms,
            # sw-images, products or releases command.
            elif self.lcname not in ConfigMeta.user_list_fields:
                if self.lcname in ConfigMeta.platforms_list:
                    cmd = ConfigMeta.platforms_cmd
                elif self.lcname in ConfigMeta.sw_images_list:
                    cmd = ConfigMeta.sw_image_cmd
                elif self.lcname in ConfigMeta.products_list:
                    cmd = ConfigMeta.products_cmd
                elif self.lcname in ConfigMeta.releases_list:
                    cmd = ConfigMeta.releases_cmd
                else:
                    cmd = 'FVLD ' + self.lcname + ' *'
                if not ConfigMeta.mdata_dict.has_key(cmd):
                    ConfigMeta.mdata_dict[cmd] = conn.fvld(self.lcname, '*')
                if self.lcname in ConfigMeta.releases_list:
                    # Create data structure for releases command once. Use
                    # same data structure for subsequent releases commnads.
                    if len(release_arr):
                        self.values_dict = release_dict
                        self.values = release_arr
                    else:
                        for line in ConfigMeta.mdata_dict[cmd]:
                            subs = line.split(':')
                            self.values_dict[subs[0]] = dict(zip(self.subfields, subs))
                            release_dict[subs[0]] = self.values_dict[subs[0]]
                            self.values.append(subs[0])
                            release_arr.append(subs[0])
                else:
                    for line in ConfigMeta.mdata_dict[cmd]:
                        subs = line.split(':')
                        self.values_dict[subs[0]] = dict(zip(self.subfields, subs))
                        self.values.append(subs[0])
        if self.ftype == 'multienum':
            cmd = 'FTYPINFO ' + self.lcname + ' separators'
            if not ConfigMeta.mdata_dict.has_key(cmd):
                ConfigMeta.mdata_dict[cmd] = conn.ftypinfo(self.lcname, 'separators')
            response = ConfigMeta.mdata_dict[cmd]
            mo = re.match(r"\'(.*)\'", response[0])
            self.separators = mo.group(1)
            self.default_separator = mo.group(1)[:1]

    def list_values(self):
        """ Return a list of valid values for the field. """
        _require_metadata(gnats.FULL_METADATA)
        return list(self.values)


class TableField(Field):
    """ A GNATS field that is a table of columns, each of which is a Field. """

    def __init__(self, name, desc, flags, db, conn):
        Field.__init__(self, name.lower(), name, desc, 'table', '', flags,
                       '', conn)
        # Reading data from data structure generated by automated script instead
        # of sending commands to gnatsd.
        cmd = 'FTYPINFO ' + self.lcname + ' columns'
        if not ConfigMeta.mdata_dict.has_key(cmd):
            ConfigMeta.mdata_dict[cmd] = conn.ftypinfo(self.lcname, 'columns')
        col_names = ConfigMeta.mdata_dict[cmd]
        self.ordered_columns = db._create_fields(conn,    #IGNORE:W0212
            ['%s.%s' % (self.lcname, col.lower()) for col in col_names],
            real_names=col_names)
        self.columns = {}
        for col in self.ordered_columns:
            # Store columns under their qualified name (field-name.col-name)
            self.columns[col.lcname] = col
            # And their unqualified name (col-name).  Also given them an
            # unqualified_name attribute
            col.unqualified_name = col.lcname.replace(self.lcname+'.', '')
            self.columns[col.unqualified_name] = col


class DatabaseHandle(object):
    """ A connection to a specific database.

    A DatabaseHandle object provides methods to query for, read and manipulate
    PRs.  It is the workhorse class of the gnats package.  It is a lightweight
    class, as almost all metadata is stored in the parent Database object.

    A given Handle object should be used for a single transaction, and
    then discarded.  A "transaction" is roughly equivalent to a single
    user action: one query, a lock-edit-unlock, creating a PR, or
    reading a PR.  If you're keeping one around for more than a few seconds
    you're probably doing something wrong.

    Creating a DatabaseHandle is quick, don't try to save time by re-using
    them, or creating a connection pool.  The gnatsd daemon is not designed
    for long-running connections, and you will likley run into unexpected
    and inexplicable errors.

    Field names are case sensitive and *must* be supplied in all-lowercase.
    """

    def __init__(self, database, username, passwd=None, conn=None):
        self.conn = database.server.get_connection(conn)
        self.database = database
        self.username = username
        self.passwd = passwd
        self.access_level = self.conn.chdb(database.name, username, passwd)

    def __str__(self):
        return "DatabaseHandle for %s" % self.database

    def __repr__(self):
        return "<%s>" % self.__str__()

    def _validate_table_columns(self, table_cols, field_names=None):
        """ Validate that table-field exists and column names are valid,
        or compile a dict of all table-fields and their columns.

        If field_names is supplied, only return table-fields listed therein.

        Canonicalizes column names to the unqualified form.

        Ensures that failures are early, and come with a clear explanation,
        versus strange KeyErrors from random internal methods.
        """
        out = {}
        if table_cols == "all":
            # make a dict of field_name: [col1, col2,...] for each table-field.
            for tfld in self.database.table_fields:
                out[tfld.lcname] = \
                    [f.unqualified_name for f in tfld.ordered_columns]
        else:
            # validate passed in dict
            for tfname, cols in table_cols.iteritems():
                try:
                    tfield = self.database.fields[tfname]
                except KeyError:
                    raise InvalidFieldNameException(
                        'Invalid table-field "%s" in table_cols.' % tfname)
                bad_colnames = []
                out[tfname] = []
                for colname in cols:
                    try:
                        out[tfname].\
                            append(tfield.columns[colname].unqualified_name)
                    except KeyError:
                        bad_colnames.append(colname)
                if bad_colnames:
                    # We only report on the bad cols for one tfield.  Oh well.
                    raise InvalidFieldNameException(
                        'Invalid column names "%s" in table_cols for '
                        'table-field "%s".' % (', '.join(bad_colnames), tfname))
        if field_names:
            return dict([(fname, cols) for fname, cols in out.iteritems()
                         if fname in field_names])
        else:
            return out

    def _get_base_prnum(self, prnum):
        """ Strip off any scope data, and convert input to a string. """
        if isinstance(prnum, basestring):
            pr_base = prnum.split("-")[0]
        # Assume it's an int, or something like it.
        else:
            pr_base = str(prnum)
        return pr_base

    def query(self, expr, field_names, sort=None, table_cols=None, pr_list=None):
        """ Run the given gnats query, returning the specified fields,
        sorted as requested.

        sort should be a list of tuples of (fieldname, 'asc|desc').
        field_names should be a list (not a tuple).

        The pr_list parameter may be a list of PR numbers to fetch.  If given,
        and expr is empty, all requested PRs will be returned.  If expr is
        also supplied, it will be used to filter the list of PRs.

        If table-fields are requested, the optional table_cols param controls
        how the values will be returned.  If it is "all", all columns of all
        table-fields will be fetched and parsed into dicts of
        {column_name:value,...} stored under the name of their table fields.
        If it is None (default) all columns will be returned as a string
        formatted in the "native" format defined by the dbconfig for the field.
        If it is a dict of the form:

        {'table_field_name': [column_name, column_name...],}

        Values for the given table-fields will be parsed into dicts, and the
        rest will be returned as strings.

        Returns a list of lists.
        """
        _require_metadata(gnats.MINIMAL_METADATA)
        _LOG.info("Query on db %s", self.database.name)
        if (expr is None or len(expr.strip()) == 0) and not pr_list:
            raise GnatsException("Must supply expr or pr_list.")
        if field_names is None or len(field_names) == 0:
            raise GnatsException("No fields selected for query.")

        if isinstance(field_names, basestring):
            field_names = [field_names]

        if table_cols:
            table_cols = self._validate_table_columns(table_cols, field_names)

        # Validate sort fields and plan the sort strategy.
        sort_fast = True
        mysort = []
        # List of enum field in requisite fields for sorting
        reqsort = []
        if sort is not None:
            for fname, direct in sort:
                fname = fname.lower()
                direct = direct.lower()
                if direct not in ('asc', 'desc'):
                    raise GnatsException("Illegal sort direction: '%s'" %
                                         direct)
                try:
                    fld = self.database.fields[fname]
                    ind = field_names.index(fld.lcname)
                except KeyError:
                    raise InvalidFieldNameException(
                        "Sort field '%s' does not exist." % fname)
                except ValueError:
                    raise GnatsException(
                        "Sort field '%s' not included in results fields." %
                                         fname)
                sort_type = fld.sorting
                if sort_type == 'table':
                    raise GnatsException("Sorting on 'table' fields is "
                                         "not supported.")
                mysort.append((fld, direct, ind, sort_type))
                if sort_type in ('enum'):
                    reqsort.append((fname,ind));
                if direct != 'asc' and sort_type not in ('enum', 'integer'):
                    # we can do a fast DSU-ish sort if the sorts are
                    # all either enum/int or ascending alpha.  Anything
                    # else requires a more complex solution
                    sort_fast = False

        self.conn.rset()
        self._format_query(field_names, table_cols)
        if expr:
            self.conn.expr(expr)

        results = self.conn.quer(pr_list, parse=True)

        if results is None or len(results) == 0:
            return []

        if table_cols:
            # Make a list of lists of column values for each table field in
            # each record in the results
            tf_indexes = []
            for tfname in table_cols.iterkeys():
                # Find the index into the results row for each table-field
                try:
                    tf_indexes.append((tfname, field_names.index(tfname)))
                except ValueError:
                    pass
            for record in results:
                for tfname, tf_index in tf_indexes:
                    vals = []
                    for row in record[tf_index].split(codes.ROW_SEP)[:-1]:
                        vals.append(row.split(codes.COL_SEP))
                    record[tf_index] = vals

        if len(results) == 1 or sort is None:
            return results

        # To sort on enum field like responsible, dev-oner, product etc.
        # Check whether user requested sort on enum fields
        if len(reqsort) > 0:
            for row in results:
                for field, ind in reqsort:
                    # Collecting values of all enum fields
                    self.database.fields[field].values.append(row[ind])
            for field, ind in reqsort:
                fld = self.database.fields[field]
                fld.values.sort()
                # Generating sort_keys array for enum fields. This will not
                # getting generated at the time of metadata load
                fld.sort_keys = dict(zip(fld.values, xrange(len(fld.values))))

        dsu_rows = []
        for row in results:
            dsu_ent = []
            for fld, direct, index, sort_type in mysort:
                if sort_type in ('integer', 'enum'):
                    if fld == self.database.number_field:
                        val = self._prnum_to_sortable(row[index])
                    elif sort_type == 'enum':
                        # XXX??? unknown values sort at -1
                        val = fld.sort_keys.get(row[index], -1)
                    else:
                        val = int(row[index])
                    if direct == 'desc':
                        val = 0 - val
                elif sort_type == 'numeric':
                    # non-integer values that need to be sorted as if they are
                    # numbers (generally release number fields)
                    val = self._numeric_sortable(row[index])
                else:
                    # Plain old alphabetical sort
                    val = row[index]
                dsu_ent.append(val)
            dsu_rows.append((tuple(dsu_ent), row))
        # Now we do the actual sort
        if sort_fast:
            # We can do a simple sort without a comparison function.
            # This is a lot faster, since it's in C.
            dsu_rows.sort()
        else:
            # Need to specify a comparison function, which will be slow
            # for large result sets
            func_parts = []
            for num, (fld, direct, index, sort_type) in enumerate(mysort):
                if sort_type in ('enum', 'integer') or direct == 'asc':
                    higher = 1
                    lower = 2
                else:
                    higher = 2
                    lower = 1
                func_parts.append("cmp(row%s[0][%s], row%s[0][%s])" %
                                  (higher, num, lower, num))
            func = "lambda row1, row2: " + " or ".join(func_parts)
            try:
                sortfunc = eval(func)
            except Exception, e:
                raise GnatsException("Error building sort comparison: %s" % e)
            dsu_rows.sort(cmp=sortfunc)
        # Undecorate the sorted rows
        rows = [r for __, r in dsu_rows]
        return rows

    def _format_query(self, field_names, table_cols):
        self.conn.qfmt(self.database.build_format(field_names))
        if table_cols:
            for tfname, cols in table_cols.iteritems():
                self.conn.tqfmt(tfname,
                    self.database.build_format(cols, table_field=tfname))

    _NUMBER_RE = re.compile(r"^\D*(\d+)\D*(\d*)\D*(\d*)\D*(\d*)")
    def _numeric_sortable(self, val):
        """ Look through the input for something that looks like a release
        number, and return a tuple of the numeric parts.  Allows sorting
        by release number.  Also works for other "piles of numbers".

        "8.5R1.3" => (8, 5, 1, 3)
        "5.0.8.5" => (5, 0, 8, 5)
        "4.0" => (4, 0)
        "1234, 5432" => (1234, 5432)

        If no digits are found, returns the input string.
        """
        if not val:
            return val
        try:
            groups = self._NUMBER_RE.match(val).groups()
            retval = []
            for chunk in groups:
                if chunk:
                    try:
                        retval.append(int(chunk))
                    except ValueError:
                        # R or B
                        retval.append(chunk.lower())
            return tuple(retval)
        except AttributeError:
            # No match found
            return val

    def _prnum_to_sortable(self, val):
        """ Turn a PR number with optional scope into an int we can
        reliably sort on.  Query results will never mix scoped
        and unscoped pr numbers, and will include the scope
        more often than not.
        """
        parts = val.split('-')
        if len(parts) == 2:
            return int("%s%s" % (parts[0], parts[1].zfill(3)))
        else:
            return int(parts[0])

    def get_pr(self, prnum, field_names='all', one_scope=False,
               table_cols="all"):
        """ Return the PR as a dict of field_name:value, axis_name:list.

        Multi-valued fields are stored under their axis name in the following
        format:

        [(axis_value, {field_name:value, field_name:value...}),
         (axis_value, {field_name:value, field_name:value...})...]

        If a builtinfield is requested, the value will be returned under the
        non-builtin name of the field.

        If one_scope is true, and a scoped PR number is submitted, only the
        requested scope will be retrieved.  Otherwise, all scopes are returned.

        If table-fields are requested, the optional table_cols param controls
        how the values will be returned.  If it is "all" (default), all columns
        of all requested table-fields will be fetched and parsed into dicts of
        {column_name:value,...} stored under the name of their table fields.
        If it is None all table-fields will be returned as strings formatted in
        the "native" format defined by the dbconfig for the field.  If it is
        a dict of the form:

        {'table_field_name': [column_name, column_name...],}

        Values for the given table-fields will be parsed into dicts, and the
        rest will be returned as strings.  Non table-field keys in the dict
        will be ignored, as a courtesy to the gnatatui web UI.

        FIXME Should we parse multienum fields into lists?
        TODO Probably flails when confronted with a multi-axis PR number.
        """
        _require_metadata(gnats.MINIMAL_METADATA)
        if not prnum:
            raise GnatsException("Must supply a PR number.")
        _LOG.info("Fetching PR %s from db %s", prnum, self.database.name)
        if not field_names:
            raise GnatsException("Must supply a list of field names.")

        multi_fields = {}
        if field_names == 'all':
            # We need to fetch the envelope fields so that we can properly
            # reconstruct the PR later.
            reg_fields = [f.lcname for f in self.database.single_valued_fields]
            reg_fields.extend([ef.lcname for ef in
                               self.database.envelope_fields.itervalues()])
            for axis, fields in self.database.multi_valued_fields.iteritems():
                multi_fields[axis.lower()] = ['scope:' + axis.lower()] + \
                    [f.lcname for f in fields]
        else:
            fields = []
            bad_fnames = []
            reg_fields = []
            for fname in field_names:
                try:
                    fields.append(self.database.fields[fname])
                except KeyError:
                    bad_fnames.append(fname)
            if bad_fnames:
                raise InvalidFieldNameException(
                    'Invalid names "%s" in field_names.' % ', '.join(bad_fnames))
            for fld in fields:
                if fld.multi_valued:
                    # TODO Not clear how things work for multi-axis fields
                    multi_fields.setdefault(fld.axis.lower(),
                        ['scope:' +fld.axis.lower()]).append(fld.lcname)
                else:
                    reg_fields.append(fld.lcname)

        # Since we have removed the column 'username' and 'datetime' from the
        # template 'audit-trail.html' to make audit-trail view collapse/expand.
        # Sometimes when it reads data from cache then it does not find those
        # fields and it throws 'TemplateSyntaxError' error message. So to avoid
        # that error added below condition. It returns in this format when
        # reads from cache. u'audit-trail': [u'info', u'row-id']
        # Iterate the loop only if 'table_cols' exist.

        if table_cols:
            for table_fld in table_cols:
                if table_fld == 'audit-trail' and \
                    len(table_cols[table_fld]) == 2:
                    table_cols = 'all'
            table_cols = self._validate_table_columns(table_cols, reg_fields)

        # Now we fetch the values
        pr_base = self._get_base_prnum(prnum)
        if reg_fields:
            # Remove Audit-Trail and Change-Log from the fields and columns for
            # not to access it from gnatsd "but directly" access the same from 
            # database to improve performance in view PR.
            check_field = reg_fields
            check_cols = table_cols
            check_at_and_cl = False
            at_cl_str = {}
            if (self.database.name == 'default' and \
                (field_names == 'all' or \
                (type(field_names) is list and len(field_names) > 2 and field_names.count('audit-trail')))):
                if check_field.count('audit-trail'):
                    check_field.remove('audit-trail')
                if type(check_cols) is dict and check_cols.has_key('audit-trail'):
                    del(check_cols['audit-trail'])
                if check_field.count('change-log'):
                    check_field.remove('change-log')
                if type(check_cols) is dict and check_cols.has_key('change-log'):
                    del(check_cols['change-log'])
                check_at_and_cl = True
                at_cl_str = self._get_change_log_audit_trail(pr_base)
            vals = self._get_pr_fields(pr_base, check_field, check_cols)
            if vals is None or len(vals) == 0:
                raise PRNotFoundException("PR %s not found" % prnum)
            pr_dict = dict(zip(reg_fields, vals[0]))
            if check_cols:
                # Make a list of dicts of colname:colvalue for each table field
                for tfname, cols in check_cols.iteritems():
                    table_vals = []
                    for row in pr_dict[tfname].split(codes.ROW_SEP)[:-1]:
                        row_dict = dict(zip(cols, row.split(codes.COL_SEP)))
                        table_vals.append(row_dict)
                    pr_dict[tfname] = table_vals
            if check_at_and_cl:
                pr_dict['audit-trail'] = at_cl_str['audit-trail']
                pr_dict['change-log'] = at_cl_str['change-log']
        else:
            pr_dict = {}

        if one_scope:
            num = prnum
        else:
            num = pr_base
        for axis, fnames in multi_fields.iteritems():
            vals = self._get_pr_fields(num, fnames)
            # Turn each scope into a field:value dict, and make a list of those
            # dicts, sorted into axis order.
            scope_list = []
            for row in vals:
                scope = dict(zip(fnames, row))
                scope_list.append((row[0], scope))
            scope_list.sort()
            pr_dict[axis] = scope_list

        return pr_dict

    def _get_pr_fields(self, prnum, field_names, table_cols=None):
        """ Fetch the requested fields for the pr. """
        self.conn.rset()
        self._format_query(field_names, table_cols)
        return self.conn.quer(prs=prnum, parse=True)

    def submit_pr(self, pr, session_id=None):
        """ Submit the pr to gnatsd and return the new PR number. """
        _LOG.info("Submitting new PR for db %s", self.database.name)
        return self.conn.subm(self.database.unparse_pr(pr), session_id)

    def lock_pr(self, prnum, user, pid, sess=''):
        """ Lock the PR for editing.

        You'll need to fetch whatever fields you want with get_pr().
        """
        _LOG.info("Locking PR %s in db %s", prnum, self.database.name)
        self.conn.lockn(self._get_base_prnum(prnum), user, pid, sess)

    def unlock_pr(self, prnum):
        """ Unlock a PR.

        Raises GnatsException if the PR isn't locked.
        """
        _LOG.info("Unlocking PR %s in db %s", prnum, self.database.name)
        return self.conn.unlk(self._get_base_prnum(prnum))

    def edit_pr(self, prnum, pr, user_address, set_flag_notify=None):
        """ Submit changes to a PR.

        The current state of the PR will be fetched from gnatsd, the supplied
        values will be inserted into pr, and the whole will be submitted to
        gnatsd.

        The submitted pr dict will be modified.

        If you need validation, call one of the Database.validate_*() methods.

        If last-modified is supplied, the value will be checked against the
        current value in the PR, and an exception will be raised if they are
        different.  This will (help) protect against edits on stale data.
        """
        _require_metadata(gnats.MINIMAL_METADATA)
        _LOG.info("User '%s' editing PR '%s' in db %s", user_address, prnum,
                   self.database.name)
        if pr is None or len(pr) == 0:
            raise GnatsException("No PR supplied for edit.")

        if not prnum:
            raise GnatsException("No PR number supplied for edit.")

        # Make sure that the user has submitted at least one editable field
        # Check regular fields, scoped fields, and finally envelope fields.
        has_editable = False
        for fld in self.database.single_valued_fields:
            if not fld.read_only and pr.has_key(fld.lcname):
                has_editable = True
                break

            # It has done for GNATS-Clarify Integration. As per the requirement,
            # user should not update 'jtac-case-id' field manually but the
            # link/unlink functionality should work.
            if fld.lcname == 'jtac-case-id':
                has_editable = True

        # For CABI project, review-status field should be read-only from
        # Gnatsweb but it should update the field value with 'Withdraw' when 
        # user click the 'withdraw' button.
        try:
            if pr['review-status'] == 'Withdraw':
                has_editable = True
        except:
            pass

        if not has_editable:
            for axis, fields in self.database.multi_valued_fields.iteritems():
                if not pr.has_key(axis):
                    continue
                ax_data = pr[axis]
                for __, ax_dict in ax_data:
                    for fld in fields:
                        if not fld.read_only and ax_dict.has_key(fld.lcname):
                            has_editable = True
                            break
        if not has_editable:
            for fld in self.database.envelope_fields.itervalues():
                if pr.has_key(fld.lcname):
                    has_editable = True
                    break
        if not has_editable:
            raise GnatsException("No editable fields supplied for PR edit.")

        if user_address is None or user_address.strip() == '':
            raise GnatsException("No user address supplied for PR edit.")

        # Supply the user's email address
        self.conn.editaddr(user_address)

        # We need to work with the entire PR
        pr_base = self._get_base_prnum(prnum)

        # Fetch the current state of the writeable non-table fields of the PR,
        # plus the last-modified field, if present.
        last_mod = self.database.builtin('last-modified')
        curr_fields = [f.lcname for f in
            self.database.ordered_fields + self.database.envelope_fields.values()
            if f.lcname == last_mod or
                not (f._really_read_only or f.ftype == 'table')]
        curr_pr = self.get_pr(pr_base, curr_fields)

        # Add logged-in user into the notify-list on click of
        # 'add me to notify' button. Also do not add logged-in user if it
        # already exist.
        if set_flag_notify:
            get_notify_list = curr_pr['notify-list']
            if get_notify_list and user_address not in \
                get_notify_list.split(','):
                pr['notify-list'] = get_notify_list + ', ' + user_address
            elif get_notify_list == '':
                pr['notify-list'] = user_address

        if curr_pr.has_key(last_mod) and \
                pr.has_key(last_mod) and \
                pr[last_mod] != curr_pr[last_mod]:
            raise LastModifiedTimeException("PR %s has been modified since you "
                "viewed it." % pr_base, old_time=pr[last_mod],
                new_time=curr_pr[last_mod])

        # Add the number field to the dict
        pr[self.database.number_field.lcname] = pr_base

        # Fill "holes" in new PR with current values
        for env_fld in self.database.envelope_fields.itervalues():
            if not pr.has_key(env_fld.lcname) and \
                    curr_pr.has_key(env_fld.lcname):
                pr[env_fld.lcname] = curr_pr[env_fld.lcname]

        return self.conn.edit(pr_base, self.database.unparse_pr(pr))

    def append_to_field(self, prnum, fname, value, username, scope=None,
                        sess=''):
        """ Append the supplied value to the named field. """
        self.conn.editaddr(username)
        return self.conn.appn(self._get_base_prnum(prnum), fname, value, scope,
                              sess)

    def replace_field(self, prnum, fname, value, username, scope=None, sess=''):
        """ Replace the named field with the supplied value. """
        self.conn.editaddr(username)
        return self.conn.repl(self._get_base_prnum(prnum), fname, value, scope,
                              sess)

    def append_to_table(self, prnum, fname, value_dict, username, sess=''):
        """ Append the supplied values to the named table. """
        self.conn.editaddr(username)
        return self.conn.tappn(self._get_base_prnum(prnum), fname, value_dict,
                              sess)

    def replace_table_row(self, prnum, fname, row_num, value_dict, username,
                          sess=''):
        """ Replace the named table row with the supplied value. """
        self.conn.editaddr(username)
        return self.conn.trepl(self._get_base_prnum(prnum), fname, row_num,
                              value_dict, sess)

    def check_pr(self, pr, initial=False):
        """ Send the full pr text to gnatsd for validation, using the CHEK
        protocol command.

        Return the error text received from gnatsd.
        If initial, validate for initial submission.

        The various validate_* methods of class Database should be used in
        preference to this method, as they work entirely with in-memory data,
        and provide errors in a useful data structure instead of a text blob.
        When submitting a PR for edit/create, gnatsd performs the same
        validations that CHEK does, making it superfluous.  This method is
        provided only for completeness.
        """
        return self.conn.chek(self.database.unparse_pr(pr), initial)

    def _get_change_log_audit_trail(self, prnum):
        import cx_Oracle
        change_audit = {}
        try:
            connection = cx_Oracle.Connection("%s/%s@%s" %
                        (codes.DEFAULT_USER, codes.DEFAULT_PASSWORD, codes.DEFAULT_DB))
            cursor = connection.cursor()
        except:
            _LOG.warning("Unable to connect to GNATS database for PR %s", prnum)
            change_audit['audit-trail'] = {}
            change_audit['change-log'] = {}
            return change_audit

        change_audit['audit-trail'] = self._exec_query(prnum, cursor, codes.AT_QUERY, codes.AT_FIELDS)
        change_audit['change-log'] = self._exec_query(prnum, cursor, codes.CL_QUERY, codes.CL_FIELDS)

        cursor.close()
        connection.close()
        return change_audit

    def _exec_query(self, prnum, cursor, query, fileds):
        out = []
        try:
            cursor.execute(query % prnum)
            for result in cursor:
                dict_index = {}
                i = 0
                for val in result:
                    if val is None:
                        val = ''
                    if fileds[i] == 'datetime':
                        val = val.replace('-0800', 'PST')
                        val = val.replace('-0700', 'PDT')
                    dict_index[unicode(fileds[i], 'iso-8859-1')] = unicode(str(val),'iso-8859-1') 
                    i = i + 1
                out.append(dict_index)
        except:
            _LOG.warning("Unable to execute query: %s for PR %s" % (query, prnum))
        return out

